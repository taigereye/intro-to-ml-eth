{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intro to ML Project\n",
    "## Task 3\n",
    "### Jan Bauer, Alaisha Sharma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from keras.utils import np_utils, to_categorical\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# same seed for consistency\n",
    "seed = 1\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y</th>\n",
       "      <th>x1</th>\n",
       "      <th>x2</th>\n",
       "      <th>x3</th>\n",
       "      <th>x4</th>\n",
       "      <th>x5</th>\n",
       "      <th>x6</th>\n",
       "      <th>x7</th>\n",
       "      <th>x8</th>\n",
       "      <th>x9</th>\n",
       "      <th>...</th>\n",
       "      <th>x111</th>\n",
       "      <th>x112</th>\n",
       "      <th>x113</th>\n",
       "      <th>x114</th>\n",
       "      <th>x115</th>\n",
       "      <th>x116</th>\n",
       "      <th>x117</th>\n",
       "      <th>x118</th>\n",
       "      <th>x119</th>\n",
       "      <th>x120</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>0.692628</td>\n",
       "      <td>0.476915</td>\n",
       "      <td>-0.979932</td>\n",
       "      <td>0.744277</td>\n",
       "      <td>0.539924</td>\n",
       "      <td>0.820458</td>\n",
       "      <td>0.851063</td>\n",
       "      <td>-0.121848</td>\n",
       "      <td>-0.588130</td>\n",
       "      <td>...</td>\n",
       "      <td>0.786940</td>\n",
       "      <td>0.751430</td>\n",
       "      <td>-0.576014</td>\n",
       "      <td>-0.452984</td>\n",
       "      <td>0.014936</td>\n",
       "      <td>-0.606131</td>\n",
       "      <td>0.533646</td>\n",
       "      <td>-0.957278</td>\n",
       "      <td>0.154000</td>\n",
       "      <td>-0.777874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>0.659780</td>\n",
       "      <td>0.261427</td>\n",
       "      <td>-0.983456</td>\n",
       "      <td>0.608041</td>\n",
       "      <td>0.539439</td>\n",
       "      <td>0.823413</td>\n",
       "      <td>0.765966</td>\n",
       "      <td>-0.270752</td>\n",
       "      <td>-0.624442</td>\n",
       "      <td>...</td>\n",
       "      <td>0.783914</td>\n",
       "      <td>0.714355</td>\n",
       "      <td>-0.569810</td>\n",
       "      <td>-0.359184</td>\n",
       "      <td>0.277566</td>\n",
       "      <td>-0.654566</td>\n",
       "      <td>0.529314</td>\n",
       "      <td>-0.957973</td>\n",
       "      <td>0.229013</td>\n",
       "      <td>-0.777375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0.705061</td>\n",
       "      <td>0.388275</td>\n",
       "      <td>-0.981143</td>\n",
       "      <td>0.628974</td>\n",
       "      <td>0.417311</td>\n",
       "      <td>0.813629</td>\n",
       "      <td>0.831153</td>\n",
       "      <td>-0.324068</td>\n",
       "      <td>-0.644861</td>\n",
       "      <td>...</td>\n",
       "      <td>0.808604</td>\n",
       "      <td>0.687422</td>\n",
       "      <td>-0.574390</td>\n",
       "      <td>-0.382889</td>\n",
       "      <td>0.123676</td>\n",
       "      <td>-0.642053</td>\n",
       "      <td>0.351704</td>\n",
       "      <td>-0.970116</td>\n",
       "      <td>0.205652</td>\n",
       "      <td>-0.757741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.743044</td>\n",
       "      <td>0.508975</td>\n",
       "      <td>-0.979041</td>\n",
       "      <td>0.763926</td>\n",
       "      <td>0.407026</td>\n",
       "      <td>0.717283</td>\n",
       "      <td>0.842587</td>\n",
       "      <td>-0.256680</td>\n",
       "      <td>-0.729415</td>\n",
       "      <td>...</td>\n",
       "      <td>0.790318</td>\n",
       "      <td>0.674969</td>\n",
       "      <td>-0.687551</td>\n",
       "      <td>-0.459537</td>\n",
       "      <td>0.074573</td>\n",
       "      <td>-0.647956</td>\n",
       "      <td>0.421374</td>\n",
       "      <td>-0.961151</td>\n",
       "      <td>0.301331</td>\n",
       "      <td>-0.771479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.669370</td>\n",
       "      <td>0.376581</td>\n",
       "      <td>-0.973238</td>\n",
       "      <td>0.657474</td>\n",
       "      <td>0.527102</td>\n",
       "      <td>0.757041</td>\n",
       "      <td>0.765099</td>\n",
       "      <td>-0.202327</td>\n",
       "      <td>-0.622846</td>\n",
       "      <td>...</td>\n",
       "      <td>0.798210</td>\n",
       "      <td>0.744071</td>\n",
       "      <td>-0.525544</td>\n",
       "      <td>-0.358159</td>\n",
       "      <td>0.305120</td>\n",
       "      <td>-0.693324</td>\n",
       "      <td>0.457829</td>\n",
       "      <td>-0.964764</td>\n",
       "      <td>0.195010</td>\n",
       "      <td>-0.791609</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 121 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   y        x1        x2        x3        x4        x5        x6        x7  \\\n",
       "0  3  0.692628  0.476915 -0.979932  0.744277  0.539924  0.820458  0.851063   \n",
       "1  4  0.659780  0.261427 -0.983456  0.608041  0.539439  0.823413  0.765966   \n",
       "2  1  0.705061  0.388275 -0.981143  0.628974  0.417311  0.813629  0.831153   \n",
       "3  3  0.743044  0.508975 -0.979041  0.763926  0.407026  0.717283  0.842587   \n",
       "4  4  0.669370  0.376581 -0.973238  0.657474  0.527102  0.757041  0.765099   \n",
       "\n",
       "         x8        x9  ...      x111      x112      x113      x114      x115  \\\n",
       "0 -0.121848 -0.588130  ...  0.786940  0.751430 -0.576014 -0.452984  0.014936   \n",
       "1 -0.270752 -0.624442  ...  0.783914  0.714355 -0.569810 -0.359184  0.277566   \n",
       "2 -0.324068 -0.644861  ...  0.808604  0.687422 -0.574390 -0.382889  0.123676   \n",
       "3 -0.256680 -0.729415  ...  0.790318  0.674969 -0.687551 -0.459537  0.074573   \n",
       "4 -0.202327 -0.622846  ...  0.798210  0.744071 -0.525544 -0.358159  0.305120   \n",
       "\n",
       "       x116      x117      x118      x119      x120  \n",
       "0 -0.606131  0.533646 -0.957278  0.154000 -0.777874  \n",
       "1 -0.654566  0.529314 -0.957973  0.229013 -0.777375  \n",
       "2 -0.642053  0.351704 -0.970116  0.205652 -0.757741  \n",
       "3 -0.647956  0.421374 -0.961151  0.301331 -0.771479  \n",
       "4 -0.693324  0.457829 -0.964764  0.195010 -0.791609  \n",
       "\n",
       "[5 rows x 121 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = pd.read_hdf(\"data/train.h5\", \"train\")\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x1</th>\n",
       "      <th>x2</th>\n",
       "      <th>x3</th>\n",
       "      <th>x4</th>\n",
       "      <th>x5</th>\n",
       "      <th>x6</th>\n",
       "      <th>x7</th>\n",
       "      <th>x8</th>\n",
       "      <th>x9</th>\n",
       "      <th>x10</th>\n",
       "      <th>...</th>\n",
       "      <th>x111</th>\n",
       "      <th>x112</th>\n",
       "      <th>x113</th>\n",
       "      <th>x114</th>\n",
       "      <th>x115</th>\n",
       "      <th>x116</th>\n",
       "      <th>x117</th>\n",
       "      <th>x118</th>\n",
       "      <th>x119</th>\n",
       "      <th>x120</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.692628</td>\n",
       "      <td>0.476915</td>\n",
       "      <td>-0.979932</td>\n",
       "      <td>0.744277</td>\n",
       "      <td>0.539924</td>\n",
       "      <td>0.820458</td>\n",
       "      <td>0.851063</td>\n",
       "      <td>-0.121848</td>\n",
       "      <td>-0.588130</td>\n",
       "      <td>0.984151</td>\n",
       "      <td>...</td>\n",
       "      <td>0.786940</td>\n",
       "      <td>0.751430</td>\n",
       "      <td>-0.576014</td>\n",
       "      <td>-0.452984</td>\n",
       "      <td>0.014936</td>\n",
       "      <td>-0.606131</td>\n",
       "      <td>0.533646</td>\n",
       "      <td>-0.957278</td>\n",
       "      <td>0.154000</td>\n",
       "      <td>-0.777874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.659780</td>\n",
       "      <td>0.261427</td>\n",
       "      <td>-0.983456</td>\n",
       "      <td>0.608041</td>\n",
       "      <td>0.539439</td>\n",
       "      <td>0.823413</td>\n",
       "      <td>0.765966</td>\n",
       "      <td>-0.270752</td>\n",
       "      <td>-0.624442</td>\n",
       "      <td>0.985527</td>\n",
       "      <td>...</td>\n",
       "      <td>0.783914</td>\n",
       "      <td>0.714355</td>\n",
       "      <td>-0.569810</td>\n",
       "      <td>-0.359184</td>\n",
       "      <td>0.277566</td>\n",
       "      <td>-0.654566</td>\n",
       "      <td>0.529314</td>\n",
       "      <td>-0.957973</td>\n",
       "      <td>0.229013</td>\n",
       "      <td>-0.777375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.705061</td>\n",
       "      <td>0.388275</td>\n",
       "      <td>-0.981143</td>\n",
       "      <td>0.628974</td>\n",
       "      <td>0.417311</td>\n",
       "      <td>0.813629</td>\n",
       "      <td>0.831153</td>\n",
       "      <td>-0.324068</td>\n",
       "      <td>-0.644861</td>\n",
       "      <td>0.984268</td>\n",
       "      <td>...</td>\n",
       "      <td>0.808604</td>\n",
       "      <td>0.687422</td>\n",
       "      <td>-0.574390</td>\n",
       "      <td>-0.382889</td>\n",
       "      <td>0.123676</td>\n",
       "      <td>-0.642053</td>\n",
       "      <td>0.351704</td>\n",
       "      <td>-0.970116</td>\n",
       "      <td>0.205652</td>\n",
       "      <td>-0.757741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.743044</td>\n",
       "      <td>0.508975</td>\n",
       "      <td>-0.979041</td>\n",
       "      <td>0.763926</td>\n",
       "      <td>0.407026</td>\n",
       "      <td>0.717283</td>\n",
       "      <td>0.842587</td>\n",
       "      <td>-0.256680</td>\n",
       "      <td>-0.729415</td>\n",
       "      <td>0.984553</td>\n",
       "      <td>...</td>\n",
       "      <td>0.790318</td>\n",
       "      <td>0.674969</td>\n",
       "      <td>-0.687551</td>\n",
       "      <td>-0.459537</td>\n",
       "      <td>0.074573</td>\n",
       "      <td>-0.647956</td>\n",
       "      <td>0.421374</td>\n",
       "      <td>-0.961151</td>\n",
       "      <td>0.301331</td>\n",
       "      <td>-0.771479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.669370</td>\n",
       "      <td>0.376581</td>\n",
       "      <td>-0.973238</td>\n",
       "      <td>0.657474</td>\n",
       "      <td>0.527102</td>\n",
       "      <td>0.757041</td>\n",
       "      <td>0.765099</td>\n",
       "      <td>-0.202327</td>\n",
       "      <td>-0.622846</td>\n",
       "      <td>0.985728</td>\n",
       "      <td>...</td>\n",
       "      <td>0.798210</td>\n",
       "      <td>0.744071</td>\n",
       "      <td>-0.525544</td>\n",
       "      <td>-0.358159</td>\n",
       "      <td>0.305120</td>\n",
       "      <td>-0.693324</td>\n",
       "      <td>0.457829</td>\n",
       "      <td>-0.964764</td>\n",
       "      <td>0.195010</td>\n",
       "      <td>-0.791609</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 120 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         x1        x2        x3        x4        x5        x6        x7  \\\n",
       "0  0.692628  0.476915 -0.979932  0.744277  0.539924  0.820458  0.851063   \n",
       "1  0.659780  0.261427 -0.983456  0.608041  0.539439  0.823413  0.765966   \n",
       "2  0.705061  0.388275 -0.981143  0.628974  0.417311  0.813629  0.831153   \n",
       "3  0.743044  0.508975 -0.979041  0.763926  0.407026  0.717283  0.842587   \n",
       "4  0.669370  0.376581 -0.973238  0.657474  0.527102  0.757041  0.765099   \n",
       "\n",
       "         x8        x9       x10  ...      x111      x112      x113      x114  \\\n",
       "0 -0.121848 -0.588130  0.984151  ...  0.786940  0.751430 -0.576014 -0.452984   \n",
       "1 -0.270752 -0.624442  0.985527  ...  0.783914  0.714355 -0.569810 -0.359184   \n",
       "2 -0.324068 -0.644861  0.984268  ...  0.808604  0.687422 -0.574390 -0.382889   \n",
       "3 -0.256680 -0.729415  0.984553  ...  0.790318  0.674969 -0.687551 -0.459537   \n",
       "4 -0.202327 -0.622846  0.985728  ...  0.798210  0.744071 -0.525544 -0.358159   \n",
       "\n",
       "       x115      x116      x117      x118      x119      x120  \n",
       "0  0.014936 -0.606131  0.533646 -0.957278  0.154000 -0.777874  \n",
       "1  0.277566 -0.654566  0.529314 -0.957973  0.229013 -0.777375  \n",
       "2  0.123676 -0.642053  0.351704 -0.970116  0.205652 -0.757741  \n",
       "3  0.074573 -0.647956  0.421374 -0.961151  0.301331 -0.771479  \n",
       "4  0.305120 -0.693324  0.457829 -0.964764  0.195010 -0.791609  \n",
       "\n",
       "[5 rows x 120 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = train_data.iloc[:,1:]\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   y\n",
       "0  3\n",
       "1  4\n",
       "2  1\n",
       "3  3\n",
       "4  4"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train = train_data.iloc[:,0:1]\n",
    "y_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x1</th>\n",
       "      <th>x2</th>\n",
       "      <th>x3</th>\n",
       "      <th>x4</th>\n",
       "      <th>x5</th>\n",
       "      <th>x6</th>\n",
       "      <th>x7</th>\n",
       "      <th>x8</th>\n",
       "      <th>x9</th>\n",
       "      <th>x10</th>\n",
       "      <th>...</th>\n",
       "      <th>x111</th>\n",
       "      <th>x112</th>\n",
       "      <th>x113</th>\n",
       "      <th>x114</th>\n",
       "      <th>x115</th>\n",
       "      <th>x116</th>\n",
       "      <th>x117</th>\n",
       "      <th>x118</th>\n",
       "      <th>x119</th>\n",
       "      <th>x120</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>45324</th>\n",
       "      <td>0.701411</td>\n",
       "      <td>0.187016</td>\n",
       "      <td>-0.982154</td>\n",
       "      <td>0.607050</td>\n",
       "      <td>0.522439</td>\n",
       "      <td>0.845936</td>\n",
       "      <td>0.760097</td>\n",
       "      <td>-0.351103</td>\n",
       "      <td>-0.574560</td>\n",
       "      <td>0.983332</td>\n",
       "      <td>...</td>\n",
       "      <td>0.785956</td>\n",
       "      <td>0.704893</td>\n",
       "      <td>-0.496666</td>\n",
       "      <td>-0.388587</td>\n",
       "      <td>0.222872</td>\n",
       "      <td>-0.593376</td>\n",
       "      <td>0.482908</td>\n",
       "      <td>-0.964796</td>\n",
       "      <td>0.142961</td>\n",
       "      <td>-0.778702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45325</th>\n",
       "      <td>0.760352</td>\n",
       "      <td>0.317576</td>\n",
       "      <td>-0.984779</td>\n",
       "      <td>0.627650</td>\n",
       "      <td>0.526251</td>\n",
       "      <td>0.811506</td>\n",
       "      <td>0.831591</td>\n",
       "      <td>-0.108528</td>\n",
       "      <td>-0.601386</td>\n",
       "      <td>0.980275</td>\n",
       "      <td>...</td>\n",
       "      <td>0.755637</td>\n",
       "      <td>0.663636</td>\n",
       "      <td>-0.561561</td>\n",
       "      <td>-0.397575</td>\n",
       "      <td>0.082542</td>\n",
       "      <td>-0.540654</td>\n",
       "      <td>0.414563</td>\n",
       "      <td>-0.974782</td>\n",
       "      <td>0.095093</td>\n",
       "      <td>-0.801885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45326</th>\n",
       "      <td>0.786375</td>\n",
       "      <td>0.531402</td>\n",
       "      <td>-0.982018</td>\n",
       "      <td>0.689513</td>\n",
       "      <td>0.516748</td>\n",
       "      <td>0.744813</td>\n",
       "      <td>0.796561</td>\n",
       "      <td>-0.236796</td>\n",
       "      <td>-0.664038</td>\n",
       "      <td>0.984294</td>\n",
       "      <td>...</td>\n",
       "      <td>0.801912</td>\n",
       "      <td>0.733216</td>\n",
       "      <td>-0.660644</td>\n",
       "      <td>-0.440287</td>\n",
       "      <td>0.224579</td>\n",
       "      <td>-0.562353</td>\n",
       "      <td>0.485940</td>\n",
       "      <td>-0.963444</td>\n",
       "      <td>0.308921</td>\n",
       "      <td>-0.796694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45327</th>\n",
       "      <td>0.619722</td>\n",
       "      <td>0.343872</td>\n",
       "      <td>-0.978162</td>\n",
       "      <td>0.685251</td>\n",
       "      <td>0.531297</td>\n",
       "      <td>0.755004</td>\n",
       "      <td>0.753230</td>\n",
       "      <td>-0.238413</td>\n",
       "      <td>-0.604895</td>\n",
       "      <td>0.983026</td>\n",
       "      <td>...</td>\n",
       "      <td>0.777083</td>\n",
       "      <td>0.700376</td>\n",
       "      <td>-0.566261</td>\n",
       "      <td>-0.301069</td>\n",
       "      <td>0.187914</td>\n",
       "      <td>-0.627751</td>\n",
       "      <td>0.503113</td>\n",
       "      <td>-0.962118</td>\n",
       "      <td>0.166841</td>\n",
       "      <td>-0.730115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45328</th>\n",
       "      <td>0.724763</td>\n",
       "      <td>0.217592</td>\n",
       "      <td>-0.975856</td>\n",
       "      <td>0.655910</td>\n",
       "      <td>0.438478</td>\n",
       "      <td>0.855352</td>\n",
       "      <td>0.794299</td>\n",
       "      <td>-0.388748</td>\n",
       "      <td>-0.638993</td>\n",
       "      <td>0.982055</td>\n",
       "      <td>...</td>\n",
       "      <td>0.789648</td>\n",
       "      <td>0.676730</td>\n",
       "      <td>-0.529255</td>\n",
       "      <td>-0.349266</td>\n",
       "      <td>0.091318</td>\n",
       "      <td>-0.632296</td>\n",
       "      <td>0.463369</td>\n",
       "      <td>-0.966323</td>\n",
       "      <td>0.032839</td>\n",
       "      <td>-0.786410</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 120 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             x1        x2        x3        x4        x5        x6        x7  \\\n",
       "45324  0.701411  0.187016 -0.982154  0.607050  0.522439  0.845936  0.760097   \n",
       "45325  0.760352  0.317576 -0.984779  0.627650  0.526251  0.811506  0.831591   \n",
       "45326  0.786375  0.531402 -0.982018  0.689513  0.516748  0.744813  0.796561   \n",
       "45327  0.619722  0.343872 -0.978162  0.685251  0.531297  0.755004  0.753230   \n",
       "45328  0.724763  0.217592 -0.975856  0.655910  0.438478  0.855352  0.794299   \n",
       "\n",
       "             x8        x9       x10  ...      x111      x112      x113  \\\n",
       "45324 -0.351103 -0.574560  0.983332  ...  0.785956  0.704893 -0.496666   \n",
       "45325 -0.108528 -0.601386  0.980275  ...  0.755637  0.663636 -0.561561   \n",
       "45326 -0.236796 -0.664038  0.984294  ...  0.801912  0.733216 -0.660644   \n",
       "45327 -0.238413 -0.604895  0.983026  ...  0.777083  0.700376 -0.566261   \n",
       "45328 -0.388748 -0.638993  0.982055  ...  0.789648  0.676730 -0.529255   \n",
       "\n",
       "           x114      x115      x116      x117      x118      x119      x120  \n",
       "45324 -0.388587  0.222872 -0.593376  0.482908 -0.964796  0.142961 -0.778702  \n",
       "45325 -0.397575  0.082542 -0.540654  0.414563 -0.974782  0.095093 -0.801885  \n",
       "45326 -0.440287  0.224579 -0.562353  0.485940 -0.963444  0.308921 -0.796694  \n",
       "45327 -0.301069  0.187914 -0.627751  0.503113 -0.962118  0.166841 -0.730115  \n",
       "45328 -0.349266  0.091318 -0.632296  0.463369 -0.966323  0.032839 -0.786410  \n",
       "\n",
       "[5 rows x 120 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test = pd.read_hdf(\"data/test.h5\", \"test\")\n",
    "X_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "scaler = StandardScaler()  \n",
    "scaler.fit(X_train)  \n",
    "X_train = scaler.transform(X_train)  \n",
    "X_test = scaler.transform(X_test)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:95: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:128: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "encoder = LabelEncoder()\n",
    "encoder.fit(y_train)\n",
    "encoded_y = encoder.transform(y_train)\n",
    "onehot_y = np_utils.to_categorical(encoded_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "45324/45324 [==============================] - 2s 44us/step - loss: 1.4878 - acc: 0.3113\n",
      "Epoch 2/100\n",
      "45324/45324 [==============================] - 1s 32us/step - loss: 1.2584 - acc: 0.3955\n",
      "Epoch 3/100\n",
      "45324/45324 [==============================] - 1s 33us/step - loss: 1.0842 - acc: 0.5401\n",
      "Epoch 4/100\n",
      "45324/45324 [==============================] - 2s 35us/step - loss: 0.9055 - acc: 0.6471\n",
      "Epoch 5/100\n",
      "45324/45324 [==============================] - 1s 31us/step - loss: 0.8012 - acc: 0.6902\n",
      "Epoch 6/100\n",
      "45324/45324 [==============================] - 1s 33us/step - loss: 0.7164 - acc: 0.7485\n",
      "Epoch 7/100\n",
      "45324/45324 [==============================] - 2s 34us/step - loss: 0.6185 - acc: 0.8037\n",
      "Epoch 8/100\n",
      "45324/45324 [==============================] - 1s 30us/step - loss: 0.5447 - acc: 0.8298\n",
      "Epoch 9/100\n",
      "45324/45324 [==============================] - 1s 30us/step - loss: 0.5038 - acc: 0.8412\n",
      "Epoch 10/100\n",
      "45324/45324 [==============================] - 1s 31us/step - loss: 0.4768 - acc: 0.8476\n",
      "Epoch 11/100\n",
      "45324/45324 [==============================] - 1s 30us/step - loss: 0.4534 - acc: 0.8560\n",
      "Epoch 12/100\n",
      "45324/45324 [==============================] - 1s 31us/step - loss: 0.4342 - acc: 0.8620\n",
      "Epoch 13/100\n",
      "45324/45324 [==============================] - 1s 31us/step - loss: 0.4179 - acc: 0.8664\n",
      "Epoch 14/100\n",
      "45324/45324 [==============================] - 1s 30us/step - loss: 0.4027 - acc: 0.8708\n",
      "Epoch 15/100\n",
      "45324/45324 [==============================] - 1s 30us/step - loss: 0.3901 - acc: 0.8756\n",
      "Epoch 16/100\n",
      "45324/45324 [==============================] - 1s 31us/step - loss: 0.3786 - acc: 0.8783\n",
      "Epoch 17/100\n",
      "45324/45324 [==============================] - 1s 30us/step - loss: 0.3685 - acc: 0.8818\n",
      "Epoch 18/100\n",
      "45324/45324 [==============================] - 1s 31us/step - loss: 0.3584 - acc: 0.8858\n",
      "Epoch 19/100\n",
      "45324/45324 [==============================] - 2s 35us/step - loss: 0.3514 - acc: 0.8862\n",
      "Epoch 20/100\n",
      "45324/45324 [==============================] - 2s 39us/step - loss: 0.3420 - acc: 0.8894\n",
      "Epoch 21/100\n",
      "45324/45324 [==============================] - 2s 45us/step - loss: 0.3356 - acc: 0.8914\n",
      "Epoch 22/100\n",
      "45324/45324 [==============================] - 1s 32us/step - loss: 0.3282 - acc: 0.8936\n",
      "Epoch 23/100\n",
      "45324/45324 [==============================] - 2s 35us/step - loss: 0.3213 - acc: 0.8954\n",
      "Epoch 24/100\n",
      "45324/45324 [==============================] - 2s 35us/step - loss: 0.3170 - acc: 0.8964\n",
      "Epoch 25/100\n",
      "45324/45324 [==============================] - 1s 30us/step - loss: 0.3119 - acc: 0.8980\n",
      "Epoch 26/100\n",
      "45324/45324 [==============================] - 2s 40us/step - loss: 0.3076 - acc: 0.9003\n",
      "Epoch 27/100\n",
      "45324/45324 [==============================] - 2s 34us/step - loss: 0.3026 - acc: 0.9016\n",
      "Epoch 28/100\n",
      "45324/45324 [==============================] - 1s 32us/step - loss: 0.2968 - acc: 0.9039\n",
      "Epoch 29/100\n",
      "45324/45324 [==============================] - 2s 43us/step - loss: 0.2921 - acc: 0.9049\n",
      "Epoch 30/100\n",
      "45324/45324 [==============================] - 1s 33us/step - loss: 0.2883 - acc: 0.9050\n",
      "Epoch 31/100\n",
      "45324/45324 [==============================] - 2s 35us/step - loss: 0.2839 - acc: 0.9068: 1s \n",
      "Epoch 32/100\n",
      "45324/45324 [==============================] - 2s 34us/step - loss: 0.2808 - acc: 0.9083\n",
      "Epoch 33/100\n",
      "45324/45324 [==============================] - 2s 36us/step - loss: 0.2769 - acc: 0.9087\n",
      "Epoch 34/100\n",
      "45324/45324 [==============================] - 2s 38us/step - loss: 0.2720 - acc: 0.9112\n",
      "Epoch 35/100\n",
      "45324/45324 [==============================] - 2s 34us/step - loss: 0.2695 - acc: 0.9118\n",
      "Epoch 36/100\n",
      "45324/45324 [==============================] - 1s 31us/step - loss: 0.2654 - acc: 0.9134\n",
      "Epoch 37/100\n",
      "45324/45324 [==============================] - 1s 31us/step - loss: 0.2619 - acc: 0.9138\n",
      "Epoch 38/100\n",
      "45324/45324 [==============================] - 1s 32us/step - loss: 0.2586 - acc: 0.9144\n",
      "Epoch 39/100\n",
      "45324/45324 [==============================] - 1s 33us/step - loss: 0.2553 - acc: 0.9162\n",
      "Epoch 40/100\n",
      "45324/45324 [==============================] - 1s 31us/step - loss: 0.2522 - acc: 0.9166\n",
      "Epoch 41/100\n",
      "45324/45324 [==============================] - 1s 31us/step - loss: 0.2484 - acc: 0.9180\n",
      "Epoch 42/100\n",
      "45324/45324 [==============================] - 1s 30us/step - loss: 0.2468 - acc: 0.9177\n",
      "Epoch 43/100\n",
      "45324/45324 [==============================] - 1s 31us/step - loss: 0.2435 - acc: 0.9194\n",
      "Epoch 44/100\n",
      "45324/45324 [==============================] - 1s 30us/step - loss: 0.2414 - acc: 0.9197\n",
      "Epoch 45/100\n",
      "45324/45324 [==============================] - 1s 30us/step - loss: 0.2390 - acc: 0.9205\n",
      "Epoch 46/100\n",
      "45324/45324 [==============================] - 1s 32us/step - loss: 0.2360 - acc: 0.9218\n",
      "Epoch 47/100\n",
      "45324/45324 [==============================] - 1s 31us/step - loss: 0.2340 - acc: 0.9228\n",
      "Epoch 48/100\n",
      "45324/45324 [==============================] - 1s 33us/step - loss: 0.2321 - acc: 0.9226\n",
      "Epoch 49/100\n",
      "45324/45324 [==============================] - 1s 30us/step - loss: 0.2309 - acc: 0.9226\n",
      "Epoch 50/100\n",
      "45324/45324 [==============================] - 1s 30us/step - loss: 0.2284 - acc: 0.9234\n",
      "Epoch 51/100\n",
      "45324/45324 [==============================] - 1s 30us/step - loss: 0.2262 - acc: 0.9251\n",
      "Epoch 52/100\n",
      "45324/45324 [==============================] - 1s 30us/step - loss: 0.2255 - acc: 0.9252\n",
      "Epoch 53/100\n",
      "45324/45324 [==============================] - 1s 30us/step - loss: 0.2248 - acc: 0.9255\n",
      "Epoch 54/100\n",
      "45324/45324 [==============================] - 1s 30us/step - loss: 0.2216 - acc: 0.9260\n",
      "Epoch 55/100\n",
      "45324/45324 [==============================] - 1s 30us/step - loss: 0.2211 - acc: 0.9262\n",
      "Epoch 56/100\n",
      "45324/45324 [==============================] - 1s 30us/step - loss: 0.2190 - acc: 0.9269\n",
      "Epoch 57/100\n",
      "45324/45324 [==============================] - 1s 30us/step - loss: 0.2182 - acc: 0.9285\n",
      "Epoch 58/100\n",
      "45324/45324 [==============================] - 1s 30us/step - loss: 0.2166 - acc: 0.9275\n",
      "Epoch 59/100\n",
      "45324/45324 [==============================] - 1s 31us/step - loss: 0.2150 - acc: 0.9275\n",
      "Epoch 60/100\n",
      "45324/45324 [==============================] - 1s 31us/step - loss: 0.2138 - acc: 0.9281\n",
      "Epoch 61/100\n",
      "45324/45324 [==============================] - 2s 35us/step - loss: 0.2118 - acc: 0.9295\n",
      "Epoch 62/100\n",
      "45324/45324 [==============================] - 1s 31us/step - loss: 0.2115 - acc: 0.9287\n",
      "Epoch 63/100\n",
      "45324/45324 [==============================] - 1s 33us/step - loss: 0.2093 - acc: 0.9308\n",
      "Epoch 64/100\n",
      "45324/45324 [==============================] - 2s 43us/step - loss: 0.2081 - acc: 0.9298\n",
      "Epoch 65/100\n",
      "45324/45324 [==============================] - 1s 32us/step - loss: 0.2084 - acc: 0.9304\n",
      "Epoch 66/100\n",
      "45324/45324 [==============================] - 1s 31us/step - loss: 0.2065 - acc: 0.9306\n",
      "Epoch 67/100\n",
      "45324/45324 [==============================] - 2s 36us/step - loss: 0.2049 - acc: 0.9308\n",
      "Epoch 68/100\n",
      "45324/45324 [==============================] - 2s 35us/step - loss: 0.2038 - acc: 0.9312\n",
      "Epoch 69/100\n",
      "45324/45324 [==============================] - 2s 33us/step - loss: 0.2028 - acc: 0.9317\n",
      "Epoch 70/100\n",
      "45324/45324 [==============================] - 2s 33us/step - loss: 0.2020 - acc: 0.9321\n",
      "Epoch 71/100\n",
      "45324/45324 [==============================] - 2s 34us/step - loss: 0.2001 - acc: 0.9323\n",
      "Epoch 72/100\n",
      "45324/45324 [==============================] - 2s 39us/step - loss: 0.1992 - acc: 0.9337\n",
      "Epoch 73/100\n",
      "45324/45324 [==============================] - 2s 34us/step - loss: 0.1981 - acc: 0.9342\n",
      "Epoch 74/100\n",
      "45324/45324 [==============================] - 2s 36us/step - loss: 0.1977 - acc: 0.9332\n",
      "Epoch 75/100\n",
      "45324/45324 [==============================] - 2s 38us/step - loss: 0.1968 - acc: 0.9344\n",
      "Epoch 76/100\n",
      "45324/45324 [==============================] - 1s 33us/step - loss: 0.1956 - acc: 0.9343\n",
      "Epoch 77/100\n",
      "45324/45324 [==============================] - 2s 36us/step - loss: 0.1947 - acc: 0.9346\n",
      "Epoch 78/100\n",
      "45324/45324 [==============================] - 2s 37us/step - loss: 0.1928 - acc: 0.9353\n",
      "Epoch 79/100\n",
      "45324/45324 [==============================] - 2s 39us/step - loss: 0.1932 - acc: 0.9344\n",
      "Epoch 80/100\n",
      "45324/45324 [==============================] - 2s 39us/step - loss: 0.1918 - acc: 0.9358\n",
      "Epoch 81/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45324/45324 [==============================] - 2s 36us/step - loss: 0.1907 - acc: 0.9366\n",
      "Epoch 82/100\n",
      "45324/45324 [==============================] - 1s 33us/step - loss: 0.1913 - acc: 0.9359\n",
      "Epoch 83/100\n",
      "45324/45324 [==============================] - 1s 33us/step - loss: 0.1888 - acc: 0.9363\n",
      "Epoch 84/100\n",
      "45324/45324 [==============================] - 2s 33us/step - loss: 0.1891 - acc: 0.9360\n",
      "Epoch 85/100\n",
      "45324/45324 [==============================] - 2s 33us/step - loss: 0.1879 - acc: 0.9366\n",
      "Epoch 86/100\n",
      "45324/45324 [==============================] - 2s 34us/step - loss: 0.1866 - acc: 0.9369\n",
      "Epoch 87/100\n",
      "45324/45324 [==============================] - 2s 34us/step - loss: 0.1858 - acc: 0.9383\n",
      "Epoch 88/100\n",
      "45324/45324 [==============================] - 2s 34us/step - loss: 0.1849 - acc: 0.9382\n",
      "Epoch 89/100\n",
      "45324/45324 [==============================] - 2s 36us/step - loss: 0.1847 - acc: 0.9373\n",
      "Epoch 90/100\n",
      "45324/45324 [==============================] - 2s 35us/step - loss: 0.1841 - acc: 0.9385\n",
      "Epoch 91/100\n",
      "45324/45324 [==============================] - 2s 36us/step - loss: 0.1819 - acc: 0.9398\n",
      "Epoch 92/100\n",
      "45324/45324 [==============================] - 2s 34us/step - loss: 0.1824 - acc: 0.9388: 1s\n",
      "Epoch 93/100\n",
      "45324/45324 [==============================] - ETA: 0s - loss: 0.1832 - acc: 0.937 - 2s 35us/step - loss: 0.1826 - acc: 0.9378\n",
      "Epoch 94/100\n",
      "45324/45324 [==============================] - 2s 42us/step - loss: 0.1795 - acc: 0.9395\n",
      "Epoch 95/100\n",
      "45324/45324 [==============================] - 2s 38us/step - loss: 0.1797 - acc: 0.9391\n",
      "Epoch 96/100\n",
      "45324/45324 [==============================] - 2s 35us/step - loss: 0.1782 - acc: 0.9399\n",
      "Epoch 97/100\n",
      "45324/45324 [==============================] - 2s 36us/step - loss: 0.1787 - acc: 0.9400\n",
      "Epoch 98/100\n",
      "45324/45324 [==============================] - 2s 37us/step - loss: 0.1774 - acc: 0.9405\n",
      "Epoch 99/100\n",
      "45324/45324 [==============================] - 2s 35us/step - loss: 0.1768 - acc: 0.9402\n",
      "Epoch 100/100\n",
      "45324/45324 [==============================] - 2s 37us/step - loss: 0.1751 - acc: 0.9412\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x127a6f4e0>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier = Sequential()\n",
    "in_dim = X_train.shape[1]\n",
    "out_dim = onehot_y.shape[1]\n",
    "\n",
    "# first hidden Layer\n",
    "classifier.add(Dense(50, activation='sigmoid', kernel_initializer='random_normal', input_dim=in_dim))\n",
    "# second hidden Layer\n",
    "classifier.add(Dense(30, activation='relu', kernel_initializer='random_normal'))\n",
    "# third hidden Layer\n",
    "classifier.add(Dense(20, activation='relu', kernel_initializer='random_normal'))\n",
    "# fourth hidden Layer\n",
    "classifier.add(Dense(15, activation='relu', kernel_initializer='random_normal'))\n",
    "# output layer\n",
    "classifier.add(Dense(out_dim, activation='softmax', kernel_initializer='random_normal'))\n",
    "\n",
    "classifier.compile(optimizer ='adam',loss='categorical_crossentropy', metrics =['accuracy'])\n",
    "classifier.fit(X_train, onehot_y, batch_size=100, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred_ker = classifier.predict(X_test)\n",
    "# find most likely category from soft max\n",
    "pred_ker = np.argmax(pred_ker, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# convert back to pandas dataframe\n",
    "X_test = pd.DataFrame(X_test)\n",
    "pred_submit = pd.DataFrame(list(zip(X_test.index.values + 45324, pred_ker)), columns=['Id', 'y'])\n",
    "final_submit = pred_submit.to_csv(\"submit.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
